{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "finnish-elevation",
   "metadata": {},
   "source": [
    "# Text2Scene\n",
    "Dies ist die Lösung der Fingerübung für das Praktikum Text2Scene des Sommersemesters 2021\n",
    "\n",
    "Autor: Xuan Anh Nguyen <br>\n",
    "Email: xuananh6077@stud.uni-frankfurt.de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "speaking-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import spacy\n",
    "import networkx as nx\n",
    "import xml.etree.ElementTree as ET\n",
    "import itertools\n",
    "import os\n",
    "import pathlib\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from spacy.training import Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "flying-disco",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_pos(ls):\n",
    "     x_set = set(ls)\n",
    "     x_dict = {}\n",
    "\n",
    "     for entry in x_set:\n",
    "          x_dict[entry] = ls.count(entry)\n",
    "\n",
    "     return x_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-immune",
   "metadata": {},
   "source": [
    "## Aufgabe 2.2 Vorverarbeitung\n",
    "Einlesen der Trainingsdaten sowie Training des Models mit dem NLP Paket **SpaCy**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "engaging-junction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n",
      "DONE\n",
      "['PLACE', 'PATH', 'SPATIAL_ENTITY', 'NONMOTION_EVENT', 'MOTION', 'SPATIAL_SIGNAL', 'MOTION_SIGNAL', 'MEASURE', 'QSLINK', 'OLINK', 'MOVELINK', 'MLINK', 'METALINK', 'MEASURELINK', 'CP', 'URL']\n"
     ]
    }
   ],
   "source": [
    "# read all valid files used for training\n",
    "\n",
    "train_data = [] # save only valid data for training (i.e. important tags)\n",
    "full_data = [] # save all (xml) data\n",
    "poss_tags = []\n",
    "\n",
    "root = pathlib.Path().absolute()\n",
    "for subdir, dirs, files in os.walk(root):\n",
    "    # skip all hidden directories and files\n",
    "    files = [f for f in files if not f[0] == '.']\n",
    "    dirs[:] = [d for d in dirs if not d[0] == '.']\n",
    "    if not subdir.startswith('.'):\n",
    "        for filename in files:\n",
    "            filepath = subdir + os.sep + filename\n",
    "            if filepath.endswith(\".xml\"):\n",
    "                # filepath will now point towards a valid .xml file\n",
    "                \n",
    "                # read and parse xml files\n",
    "                tree = ET.parse(filepath)\n",
    "                root = tree.getroot()\n",
    "                \n",
    "                full_data.append(root)\n",
    "                \n",
    "                # label text with entities \n",
    "                entities = []\n",
    "                for elem in root[1]:\n",
    "                    # filter non usable entries\n",
    "                    if (elem.get('start') != None) and (elem.get('end') != None) and (elem.get('start') != '-1') and (elem.get('end') != '-1'):\n",
    "                        new_ent = (int(elem.get('start')), int(elem.get('end')), elem.tag)\n",
    "                        entities.append(new_ent)\n",
    "                    if elem.tag not in poss_tags:\n",
    "                        poss_tags.append(elem.tag)\n",
    "                        \n",
    "                # save the 2 special xml files extra so we can access them easier later\n",
    "                if filepath.endswith(\"Bicycles.xml\"):\n",
    "                    print(\"confirmed\")\n",
    "                    special1 = root\n",
    "                elif filepath.endswith(\"Highlights_of_the_Prado_Museum.xml\"):\n",
    "                    print(\"confirmed\")\n",
    "                    special2 = root\n",
    "\n",
    "                        \n",
    "                train_data.append((root[0].text, {'entities': entities}))\n",
    "    \n",
    "# print(TRAIN_DATA[1][0])\n",
    "print(poss_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "worthy-force",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "['ner']\n",
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 3/60 [00:00<00:06,  9.23it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[E103] Trying to set conflicting doc.ents: '(1577, 1581, 'MOTION')' and '(1577, 1581, 'MOTION')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-197-cea471f4e3f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_DATA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             nlp.update(\n\u001b[0;32m---> 36\u001b[0;31m                 \u001b[0;34m[\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/training/example.pyx\u001b[0m in \u001b[0;36mspacy.training.example.Example.from_dict\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/training/example.pyx\u001b[0m in \u001b[0;36mspacy.training.example.annotations_to_doc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/training/example.pyx\u001b[0m in \u001b[0;36mspacy.training.example._add_entities_to_doc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/spacy/training/iob_utils.py\u001b[0m in \u001b[0;36moffsets_to_biluo_tags\u001b[0;34m(doc, entities, missing)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtoken_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_char\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtoken_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens_in_ents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    105\u001b[0m                         Errors.E103.format(\n\u001b[1;32m    106\u001b[0m                             span1=(\n",
      "\u001b[0;31mValueError\u001b[0m: [E103] Trying to set conflicting doc.ents: '(1577, 1581, 'MOTION')' and '(1577, 1581, 'MOTION')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead."
     ]
    }
   ],
   "source": [
    "# train the model with our training data\n",
    "\n",
    "model = None\n",
    "n_iter=100\n",
    "\n",
    "if model is not None:\n",
    "    nlp = spacy.load(model)  \n",
    "    print(\"Loaded model '%s'\" % model)\n",
    "else:\n",
    "    nlp = spacy.blank('en')  \n",
    "    print(\"Created blank 'en' model\")\n",
    "\n",
    "#set up the pipeline\n",
    "\n",
    "if 'ner' not in nlp.pipe_names:\n",
    "    nlp.add_pipe('ner', last=True)\n",
    "else:\n",
    "    ner = nlp.get_pipe('ner')\n",
    "\n",
    "\n",
    "for _, annotations in TRAIN_DATA:\n",
    "    for ent in annotations.get('entities'):\n",
    "        ner.add_label(ent[2])\n",
    "     \n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train NER\n",
    "    optimizer = nlp.begin_training()\n",
    "    for itn in range(n_iter):\n",
    "        # random.shuffle(TRAIN_DATA)\n",
    "        losses = {}\n",
    "        doc = nlp.make_doc(root[0].text)\n",
    "        print(len(TRAIN_DATA))\n",
    "        for text, annotations in tqdm(TRAIN_DATA):\n",
    "            nlp.update(\n",
    "                [Example.from_dict(nlp.make_doc(text), annotations)],  \n",
    "                drop=0.4,  \n",
    "                sgd=optimizer,\n",
    "                losses=losses)\n",
    "        print(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "hairy-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load English tokenizer, tagger, parser and NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-sympathy",
   "metadata": {},
   "source": [
    "## 2.3 Auswertung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-multiple",
   "metadata": {},
   "source": [
    "Wie oft kommen welche PoS-Tags vor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "alien-object",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aufgabe 1:\n",
      "('VERB', 3060)\n",
      "('ADP', 3211)\n",
      "('SCONJ', 311)\n",
      "('ADV', 1360)\n",
      "('SYM', 24)\n",
      "('PRON', 1701)\n",
      "('INTJ', 12)\n",
      "('PUNCT', 3636)\n",
      "('X', 26)\n",
      "('SPACE', 837)\n",
      "('NOUN', 5391)\n",
      "('PROPN', 1972)\n",
      "('ADJ', 1907)\n",
      "('DET', 3062)\n",
      "('PART', 540)\n",
      "('AUX', 932)\n",
      "('NUM', 648)\n",
      "('CCONJ', 862)\n"
     ]
    }
   ],
   "source": [
    "pos_ls = []\n",
    "for text, _ in train_data:\n",
    "    doc = nlp(text)\n",
    "    for token in doc:\n",
    "        pos_ls.append(token.pos_)\n",
    "pos_dic = count_pos(pos_ls)\n",
    "print(\"Aufgabe 1:\")\n",
    "print(*pos_dic.items(), sep=\"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-court",
   "metadata": {},
   "source": [
    "Wie viele [SpatialEntities, Places, Motions, Locations, Signals, QsLinks, OLinks] gibt es?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "sublime-danger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aufgabe 2:\n",
      "('URL', 51)\n",
      "('SPATIAL_SIGNAL', 2193)\n",
      "('MLINK', 132)\n",
      "('NONMOTION_EVENT', 1053)\n",
      "('PLACE', 5712)\n",
      "('METALINK', 5565)\n",
      "('QSLINK', 2991)\n",
      "('MEASURE', 516)\n",
      "('CP', 51)\n",
      "('PATH', 1353)\n",
      "('MOTION_SIGNAL', 1614)\n",
      "('MOTION', 2421)\n",
      "('SPATIAL_ENTITY', 4419)\n",
      "('MEASURELINK', 279)\n",
      "('MOVELINK', 2526)\n",
      "('OLINK', 753)\n"
     ]
    }
   ],
   "source": [
    "ent_ls = []\n",
    "for data in full_data:\n",
    "    for elem in data[1]:\n",
    "         ls.append(elem.tag)\n",
    "\n",
    "ent_dic = count_pos(ls)\n",
    "print(\"Aufgabe 2:\")\n",
    "print(*ent_dic.items(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-hygiene",
   "metadata": {},
   "source": [
    "Wie oft kommen welche QsLink Typen vor? (DC,EC, ...)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "individual-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aufgabe 3:\n",
      "('', 2)\n",
      "('EQ', 35)\n",
      "('NTPP', 42)\n",
      "('DC', 42)\n",
      "('PO', 12)\n",
      "('EC', 203)\n",
      "('IN', 604)\n",
      "('OUT', 3)\n",
      "('TPP', 54)\n"
     ]
    }
   ],
   "source": [
    "links_ls = []\n",
    "for data in full_data:\n",
    "    for elem in data[1]:\n",
    "        if elem.tag == \"QSLINK\":\n",
    "            links_ls.append(elem.get('relType'))\n",
    "            \n",
    "links_dic = count_pos(links_ls)\n",
    "print(\"Aufgabe 3:\")\n",
    "print(*links_dic.items(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-change",
   "metadata": {},
   "source": [
    "Verteilung der Satzlänge graphisch darstellen (x: Satzlänge, y: Wie häufig)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "billion-culture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent_ls = []\n",
    "for text, _ in train_data:\n",
    "    doc = nlp(text)\n",
    "    for sent in doc.sents:\n",
    "        # find length by counting whitespaces in the sentence\n",
    "        temp1 = sent.text\n",
    "        temp2 = temp1.replace(' ', '')\n",
    "        spaces = len(temp1) - len(temp2)\n",
    "        sent_ls.append(spaces+1)\n",
    "# map lengths to amount of times it appereard\n",
    "distribution = count_pos(sent_ls)\n",
    "plt.bar(list(distribution.keys()), list(distribution.values()))\n",
    "plt.title(\"Satzlängen\")\n",
    "plt.xlabel(\"Satzlängen\")\n",
    "plt.ylabel(\"Häufigkeiten\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "practical-collaboration",
   "metadata": {},
   "source": [
    "Welche Links (QSLinks, OLinks) werden von welchen Präpositionen (markiert durch SPATIAL_SIGNAL) getriggert (z.B. wie oft werden QSLinks durch die Präposition „on“ getriggert)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "mineral-handle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aufgabe 5:\n",
      "\n",
      "Qslink trigger:\n",
      "('along', 14)\n",
      "('upon', 1)\n",
      "('part         of', 1)\n",
      "('where', 70)\n",
      "('far from', 3)\n",
      "('covering', 1)\n",
      "('bordering', 1)\n",
      "('inside of', 1)\n",
      "('inhabited', 1)\n",
      "('In', 22)\n",
      "('Down', 1)\n",
      "('away', 2)\n",
      "('full of', 10)\n",
      "('apart from', 1)\n",
      "('house', 1)\n",
      "('including', 3)\n",
      "('has', 2)\n",
      "('next to', 10)\n",
      "('under', 2)\n",
      "('of', 44)\n",
      "('surrounded', 2)\n",
      "('overlooking', 2)\n",
      "('coiling up', 1)\n",
      "('on top of', 1)\n",
      "('contain', 4)\n",
      "('apart', 1)\n",
      "('behind', 1)\n",
      "('surmounted', 1)\n",
      "('on', 77)\n",
      "('filled', 3)\n",
      "('from', 3)\n",
      "('up to', 1)\n",
      "('contains', 1)\n",
      "('on top', 3)\n",
      "('covered', 5)\n",
      "('through', 4)\n",
      "('outside', 2)\n",
      "('directly beneath', 1)\n",
      "('Everywhere', 1)\n",
      "('inside', 4)\n",
      "('for', 1)\n",
      "('afar', 1)\n",
      "('into', 1)\n",
      "('after', 1)\n",
      "('away from', 4)\n",
      "('houses', 11)\n",
      "('beside', 1)\n",
      "('out of', 1)\n",
      "('to', 2)\n",
      "('packed with', 1)\n",
      "('around', 4)\n",
      "('between', 5)\n",
      "('In front of', 1)\n",
      "('packed', 1)\n",
      "('with', 15)\n",
      "('about', 1)\n",
      "('Along', 1)\n",
      "('stocked', 1)\n",
      "('over', 2)\n",
      "('further', 1)\n",
      "('in', 238)\n",
      "('up', 1)\n",
      "('restricted', 1)\n",
      "('in front of', 1)\n",
      "('connects', 4)\n",
      "('at', 55)\n",
      "('line', 1)\n",
      "('atop', 2)\n",
      "('adjacent to', 1)\n",
      "('On', 4)\n",
      "('against', 1)\n",
      "('surrounding', 3)\n",
      "('across', 2)\n",
      "('At', 7)\n",
      "\n",
      "Olink trigger:\n",
      "('along', 14)\n",
      "('upon', 1)\n",
      "('south of', 2)\n",
      "('on the right', 1)\n",
      "('east of', 3)\n",
      "('to SW', 1)\n",
      "('next door to', 1)\n",
      "('across from', 1)\n",
      "('northeast', 1)\n",
      "('Southeast of', 2)\n",
      "('Down', 2)\n",
      "('on your left', 1)\n",
      "('neighboring', 1)\n",
      "('South\\xadeast of', 1)\n",
      "('next to', 12)\n",
      "('under', 3)\n",
      "('upstream from', 1)\n",
      "('of', 3)\n",
      "('surrounded', 4)\n",
      "('overlooking', 3)\n",
      "('in that direction', 1)\n",
      "('below', 4)\n",
      "('coiling up', 1)\n",
      "('on top of', 1)\n",
      "('north of', 2)\n",
      "('overlook', 1)\n",
      "('West of', 1)\n",
      "('to the left', 1)\n",
      "('behind', 3)\n",
      "('in the direction to', 1)\n",
      "('on', 47)\n",
      "('up to', 1)\n",
      "('south', 4)\n",
      "('directly beneath', 1)\n",
      "('southwest', 1)\n",
      "('covered', 5)\n",
      "('on top', 3)\n",
      "('toward', 1)\n",
      "('surmounted', 1)\n",
      "('east', 2)\n",
      "('west', 1)\n",
      "('facing', 1)\n",
      "('alongside', 1)\n",
      "('down', 5)\n",
      "('to the west from', 1)\n",
      "('to', 3)\n",
      "('beside', 1)\n",
      "('around', 3)\n",
      "('between', 9)\n",
      "('In front of', 1)\n",
      "('Along', 1)\n",
      "('north', 2)\n",
      "('over', 7)\n",
      "('backwards', 1)\n",
      "('in', 2)\n",
      "('up', 5)\n",
      "('above', 4)\n",
      "('in front of', 2)\n",
      "('Facing', 1)\n",
      "('Across', 1)\n",
      "('adjacent to', 1)\n",
      "('line', 1)\n",
      "('atop', 2)\n",
      "('On', 2)\n",
      "('surrounding', 3)\n",
      "('across', 1)\n",
      "('beneath', 4)\n"
     ]
    }
   ],
   "source": [
    "qs_trigger = []\n",
    "o_trigger = []\n",
    "\n",
    "# collect all triggers\n",
    "for data in full_data:\n",
    "    temp_qs = []\n",
    "    temp_o = []\n",
    "    trigg_dic = {}\n",
    "    \n",
    "    # add all triggers ONLY with their id\n",
    "    for elem in data[1]:\n",
    "        if elem.tag == \"QSLINK\":\n",
    "            temp_qs.append(elem.attrib['trigger'])\n",
    "        elif elem.tag == \"OLINK\":\n",
    "            temp_o.append(elem.attrib['trigger'])\n",
    "        if elem.tag == \"SPATIAL_SIGNAL\":\n",
    "            trigg_dic[elem.get('id')] = elem.get('text')\n",
    "\n",
    "    # replace trigger id with their respective texts\n",
    "    for i in range(len(temp_qs)):\n",
    "        try:\n",
    "            qs_trigger.append(trigg_dic[temp_qs[i]])\n",
    "        except:\n",
    "            pass\n",
    "    for i in range(len(temp_o)):\n",
    "        try:\n",
    "            o_trigger.append(trigg_dic[temp_o[i]])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "qs_trigger = count_pos(qs_trigger)\n",
    "o_trigger = count_pos(o_trigger)\n",
    "\n",
    "print(\"Aufgabe 5:\")\n",
    "print(\"\\nQslink trigger:\", *qs_trigger.items(), sep=\"\\n\")\n",
    "print(\"\\nOlink trigger:\", *o_trigger.items(), sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-slope",
   "metadata": {},
   "source": [
    "Welches sind die fünf häufigsten „MOTION“ Verben (und wie oft kommen diese vor)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "seeing-think",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aufgabe 6:\n",
      "('bike', 72)\n",
      "('visit', 40)\n",
      "('go', 38)\n",
      "('ride', 36)\n",
      "('leave', 33)\n"
     ]
    }
   ],
   "source": [
    "lemma_verbs = []   # only collect lemma from verbs\n",
    "for data in full_data:\n",
    "    # collect all different motion verbs\n",
    "    verbs = []  \n",
    "    for elem in data[1]:\n",
    "        if elem.tag == \"MOTION\":\n",
    "            verbs.append(elem.attrib['text'])\n",
    "            \n",
    "    # only add their lemma to the actual list\n",
    "    doc = nlp(data[0].text)\n",
    "    for token in doc:\n",
    "        if token.text in verbs:\n",
    "            lemma_verbs.append(token.lemma_)\n",
    "\n",
    "lemma_verbs = count_pos(lemma_verbs)\n",
    "lemma_verbs = sorted(lemma_verbs.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"Aufgabe 6:\", *lemma_verbs[0:5], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personalized-shooting",
   "metadata": {},
   "source": [
    "## 2.4 Visualisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premier-format",
   "metadata": {},
   "source": [
    "Graphische Darstellung von Verbindungen zwischen Entitäten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informative-growth",
   "metadata": {},
   "source": [
    "**Bicycle.xml**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "future-anime",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'special1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-265-f7e2b0780eb9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspecial1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcolor_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcounter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'special1' is not defined"
     ]
    }
   ],
   "source": [
    "print(special1)\n",
    "\n",
    "G = nx.Graph()\n",
    "color_map = []\n",
    "counter = 0\n",
    "for elem in root[1]:\n",
    "     if elem.tag == \"SPATIAL_ENTITY\":\n",
    "          G.add_node(elem.attrib['text'])\n",
    "\n",
    "nx.draw(G, node_color='r', with_labels=True)\n",
    "\n",
    "for elem in root[1]:\n",
    "     if elem.tag == \"PLACE\":\n",
    "          G.add_node(elem.attrib['text'])\n",
    "\n",
    "nx.draw(G, node_color='b', with_labels=True)\n",
    "\n",
    "\n",
    "for elem in root[1]:\n",
    "     if elem.tag == \"LOCATION\":\n",
    "          G.add_node(elem.attrib['text'])\n",
    "\n",
    "nx.draw(G, node_color='g', with_labels=True)\n",
    "\n",
    "\n",
    "for elem in root[1]:\n",
    "     if elem.tag == \"PATH\":\n",
    "          G.add_node(elem.attrib['text'])\n",
    "\n",
    "nx.draw(G, node_color='w', with_labels=True)\n",
    "\n",
    "\n",
    "for elem in root[1]:\n",
    "     if elem.tag == \"NONMOTIONEVENT\":\n",
    "          G.add_node(elem.attrib['text'])\n",
    "\n",
    "nx.draw(G, node_color='y', with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wicked-defeat",
   "metadata": {},
   "source": [
    "**Highlights_of_the_Prado_Museum.xml**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spread-malaysia",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signal-power",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-xerox",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
